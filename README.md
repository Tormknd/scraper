# ğŸ¤– Scraper-LLM - Extracteur Web Intelligent

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.100+-green.svg)](https://fastapi.tiangolo.com/)
[![Next.js](https://img.shields.io/badge/Next.js-15.4+-black.svg)](https://nextjs.org/)
[![OpenAI](https://img.shields.io/badge/OpenAI-GPT--4o--mini-purple.svg)](https://openai.com/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

> **Scraper-LLM** est une application qui combine la puissance de l'IA (OpenAI) avec le web scraping pour extraire automatiquement des donnÃ©es structurÃ©es de n'importe quel site web. L'application utilise l'intelligence artificielle pour comprendre le contenu des pages et extraire intelligemment les produits, images et prix.

## âœ¨ FonctionnalitÃ©s Principales

- ğŸ§  **Extraction Intelligente** : Utilise GPT-4o-mini pour analyser et extraire les donnÃ©es pertinentes
- ğŸ–¼ï¸ **TÃ©lÃ©chargement d'Images** : TÃ©lÃ©charge automatiquement les images et les stocke localement
- ğŸ¯ **Extraction StructurÃ©e** : Retourne des donnÃ©es JSON organisÃ©es (titre, prix, image)
- ğŸŒ **Interface Web Moderne** : Interface terminal interactive inspirÃ©e de vzlabs.ai
- âš¡ **Performance OptimisÃ©e** : Gestion des erreurs, retry automatique, dÃ©duplication
- ğŸ”’ **SÃ©curitÃ©** : Validation des URLs, gestion des timeouts, sanitisation

## ğŸ—ï¸ Architecture

```
ScrapingTest/
â”œâ”€â”€ backend/                 # API FastAPI
â”‚   â”œâ”€â”€ main.py             # Serveur FastAPI
â”‚   â”œâ”€â”€ scraper.py          # Logique de scraping avec OpenAI
â”‚   â”œâ”€â”€ requirements.txt    # DÃ©pendances Python
â”‚   â””â”€â”€ images/             # Images tÃ©lÃ©chargÃ©es
â””â”€â”€ frontend/               # Interface Next.js
    â”œâ”€â”€ src/app/page.tsx    # Interface terminal
    â”œâ”€â”€ package.json        # DÃ©pendances Node.js
    â””â”€â”€ components/         # Composants UI
```

## ğŸš€ Installation et Configuration

### PrÃ©requis

- **Python 3.8+**
- **Node.js 18+**
- **ClÃ© API OpenAI** (gratuite ou payante)

### 1. Cloner le Repository

```bash
git clone https://github.com/Tormknd/scraper.git
cd scraper
```

### 2. Configuration du Backend

```bash
cd backend

# Installer les dÃ©pendances Python
pip install -r requirements.txt

# Configurer les variables d'environnement
cp env.example .env
```

Ã‰ditez le fichier `.env` :
```env
OPENAI_API_KEY=sk-votre-clÃ©-api-openai
# Optionnel : changer le modÃ¨le OpenAI
# OPENAI_MODEL=gpt-4o-mini
```

### 3. Configuration du Frontend

```bash
cd ../frontend

# Installer les dÃ©pendances Node.js
npm install
```

## ğŸ® Utilisation

### DÃ©marrage des Services

**Terminal 1 - Backend :**
```bash
cd backend
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

**Terminal 2 - Frontend :**
```bash
cd frontend
npm run dev
```

L'application sera accessible sur `http://localhost:3000`

### Interface Terminal

L'interface propose une expÃ©rience terminal interactive avec les commandes suivantes :

```bash
# Afficher l'aide
help

# Scraper une URL
scrap https://example.com

# Effacer l'Ã©cran
clear

# Navigation dans l'historique
â†‘ / â†“  # Naviguer dans les 10 derniÃ¨res commandes
```

### Exemple d'Utilisation

1. Ouvrez `http://localhost:3000`
2. Tapez `scrap https://www.example-ecommerce.com`
3. L'IA analyse la page et extrait automatiquement :
   - Les titres des produits
   - Les prix (si disponibles)
   - Les images (tÃ©lÃ©chargÃ©es localement)
4. Les rÃ©sultats s'affichent en JSON et les images dans une galerie

## ğŸ”§ Configuration AvancÃ©e

### Variables d'Environnement

| Variable | Description | DÃ©faut |
|----------|-------------|---------|
| `OPENAI_API_KEY` | ClÃ© API OpenAI (requise) | - |
| `OPENAI_MODEL` | ModÃ¨le OpenAI Ã  utiliser | `gpt-4o-mini` |

### ParamÃ¨tres de Performance

Dans `backend/scraper.py` :
```python
TIMEOUT     = 10        # Timeout HTTP (secondes)
RETRIES     = 3         # Nombre de tentatives
PAUSE_IMG   = 0.4       # Pause entre tÃ©lÃ©chargements d'images
MAX_TOKENS  = 11_000    # Limite de tokens pour OpenAI
```

## ğŸ“Š Format des DonnÃ©es

L'API retourne un JSON structurÃ© :

```json
{
  "items": [
    {
      "title": "Nom du produit",
      "price": "29.99 â‚¬",
      "img": "https://example.com/image.jpg",
      "img_local": "/images/image.jpg"
    }
  ]
}
```

## ğŸ› ï¸ API Endpoints

### POST `/scrape`

Extrait les donnÃ©es d'une URL donnÃ©e.

**RequÃªte :**
```json
{
  "url": "https://example.com"
}
```

**RÃ©ponse :**
```json
{
  "items": [
    {
      "title": "Produit 1",
      "price": "19.99 â‚¬",
      "img": "https://example.com/img1.jpg",
      "img_local": "/images/img1.jpg"
    }
  ]
}
```

## ğŸ” FonctionnalitÃ©s Techniques

### Intelligence Artificielle
- **ModÃ¨le** : GPT-4o-mini (optimisÃ© pour la vitesse et le coÃ»t)
- **Prompt** : Analyse du HTML pour extraire les Ã©lÃ©ments pertinents
- **SchÃ©ma** : Structure JSON prÃ©dÃ©finie pour la cohÃ©rence

### Gestion des Images
- **TÃ©lÃ©chargement automatique** vers le dossier `backend/images/`
- **DÃ©duplication** basÃ©e sur les URLs d'images
- **Support multi-format** : JPEG, PNG, WebP, AVIF, GIF
- **Fallback** : URL distante si tÃ©lÃ©chargement Ã©choue

### Robustesse
- **Retry automatique** pour les erreurs HTTP 5xx
- **Timeout configurable** pour Ã©viter les blocages
- **Gestion d'erreurs** complÃ¨te avec messages explicites
- **Sanitisation des URLs** pour Ã©viter les injections

## ğŸ¨ Interface Utilisateur

L'interface s'inspire des terminaux modernes avec :
- **Design sombre** pour rÃ©duire la fatigue oculaire
- **Typographie monospace** pour l'aspect technique
- **Animations fluides** avec Framer Motion
- **Galerie d'images** responsive
- **Navigation clavier** complÃ¨te

## ğŸš¨ Gestion des Erreurs

L'application gÃ¨re automatiquement :
- **Erreurs rÃ©seau** : Retry avec backoff exponentiel
- **Timeouts** : Limite configurable pour Ã©viter les blocages
- **Erreurs OpenAI** : Messages d'erreur explicites
- **Images manquantes** : Fallback vers URL distante
- **HTML malformÃ©** : Nettoyage automatique avec BeautifulSoup

## ğŸ“ˆ Performance

- **Extraction rapide** : OptimisÃ© pour les sites e-commerce
- **Cache d'images** : Ã‰vite les tÃ©lÃ©chargements redondants
- **Limite de tokens** : ContrÃ´le des coÃ»ts OpenAI
- **Concurrence** : Gestion asynchrone des requÃªtes

## ğŸ”’ SÃ©curitÃ©

- **Validation des URLs** : VÃ©rification du format et du protocole
- **Sanitisation** : Encodage des caractÃ¨res spÃ©ciaux
- **User-Agent** : Identification claire du bot
- **Rate limiting** : Pause entre les tÃ©lÃ©chargements d'images

## ğŸ¤ Contribution

Les contributions sont les bienvenues ! Voici comment contribuer :

1. **Fork** le projet
2. **CrÃ©ez** une branche pour votre fonctionnalitÃ©
3. **Commitez** vos changements
4. **Poussez** vers la branche
5. **Ouvrez** une Pull Request

### AmÃ©liorations SuggÃ©rÃ©es

- [ ] Support de l'authentification pour les sites protÃ©gÃ©s
- [ ] Extraction de donnÃ©es plus complexes (avis, descriptions)
- [ ] Interface d'administration pour gÃ©rer les extractions
- [ ] Support de l'export vers CSV/Excel
- [ ] IntÃ©gration avec d'autres modÃ¨les d'IA

## ğŸ“„ Licence

Ce projet est sous licence MIT. Voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.

## ğŸ™ Remerciements

- **OpenAI** pour l'accÃ¨s Ã  leurs modÃ¨les d'IA
- **FastAPI** pour le framework backend performant
- **Next.js** pour l'interface utilisateur moderne
- **BeautifulSoup** pour le parsing HTML robuste

## ğŸ“ Support

Pour toute question ou problÃ¨me :
- **Issues GitHub** : [CrÃ©er une issue](https://github.com/Tormknd/scraper/issues)
- **Email** : [Votre email]

---

**Scraper-LLM** - Transformez n'importe quel site web en donnÃ©es structurÃ©es avec l'intelligence artificielle ! ğŸš€ 