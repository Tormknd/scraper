# ğŸ¤– Scraper-LLM - Extracteur Web Intelligent

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.100+-green.svg)](https://fastapi.tiangolo.com/)
[![Next.js](https://img.shields.io/badge/Next.js-15.4+-black.svg)](https://nextjs.org/)
[![OpenAI](https://img.shields.io/badge/OpenAI-GPT--4o--mini-purple.svg)](https://openai.com/)

> **Scraper-LLM** est une application rÃ©volutionnaire qui combine l'intelligence artificielle (OpenAI) avec des techniques avancÃ©es de web scraping pour extraire automatiquement des donnÃ©es structurÃ©es de n'importe quel site web. L'application utilise l'IA pour comprendre le contenu des pages et extraire intelligemment les produits, images, prix et informations pertinentes.

## âœ¨ FonctionnalitÃ©s Principales

- ğŸ§  **Extraction Intelligente** : Utilise GPT-4o-mini pour analyser et extraire les donnÃ©es pertinentes
- ğŸ–¼ï¸ **TÃ©lÃ©chargement d'Images** : TÃ©lÃ©charge automatiquement les images et les stocke localement
- ğŸ¯ **Extraction StructurÃ©e** : Retourne des donnÃ©es JSON organisÃ©es (titre, prix, image, description)
- âš¡ **Performance OptimisÃ©e** : Gestion des erreurs, retry automatique, dÃ©duplication
- ğŸ”’ **SÃ©curitÃ© AvancÃ©e** : Validation des URLs, gestion des timeouts, sanitisation
- ğŸŒ **Rendu JavaScript** : Support des sites dynamiques avec Playwright et Selenium
- ğŸ“° **Extraction de Contenu** : Algorithmes de lisibilitÃ© pour un contenu de qualitÃ©
- ğŸ·ï¸ **DonnÃ©es StructurÃ©es** : Extraction des mÃ©tadonnÃ©es Schema.org, Open Graph, etc.

## ğŸ—ï¸ Architecture

```
ScrapingTest/
â”œâ”€â”€ backend/                 # API FastAPI
â”‚   â”œâ”€â”€ main.py             # Serveur FastAPI principal
â”‚   â”œâ”€â”€ scraper.py          # Scraper de base avec OpenAI
â”‚   â”œâ”€â”€ advanced_scraper.py # Scraper avancÃ© avec multiples mÃ©thodes
â”‚   â”œâ”€â”€ requirements.txt    # DÃ©pendances Python
â”‚   â”œâ”€â”€ env.example         # Configuration d'environnement
â”‚   â””â”€â”€ images/             # Images tÃ©lÃ©chargÃ©es
â””â”€â”€ frontend/               # Interface Next.js
    â”œâ”€â”€ src/app/page.tsx    # Interface terminal interactive
    â”œâ”€â”€ package.json        # DÃ©pendances Node.js
    â””â”€â”€ components/         # Composants UI
```

## ğŸš€ Installation Rapide

### PrÃ©requis

- **Python 3.8+**
- **Node.js 18+**
- **ClÃ© API OpenAI** (gratuite ou payante)

### 1. Cloner et Installer

```bash
# Cloner le repository
git clone https://github.com/Tormknd/scraper.git
cd scraper

# Configuration du backend
cd backend
pip install -r requirements.txt

# Configuration du frontend
cd ../frontend
npm install
```

### 2. Configuration

```bash
# Dans le dossier backend
cp env.example .env
```

Ã‰ditez le fichier `backend/.env` :
```env
OPENAI_API_KEY=sk-votre-clÃ©-api-openai
# Optionnel : changer le modÃ¨le OpenAI
# OPENAI_MODEL=gpt-4o-mini
```

### 3. DÃ©marrer l'Application

**Terminal 1 - Backend :**
```bash
cd backend
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

**Terminal 2 - Frontend :**
```bash
cd frontend
npm run dev
```

ğŸ‰ **L'application est maintenant accessible sur `http://localhost:3000`**

## ğŸ® Utilisation Simple

### Interface Terminal Interactive

1. Ouvrez `http://localhost:3000`
2. Utilisez les commandes suivantes :

```bash
# Afficher l'aide
help

# Scraper une URL (mÃ©thode de base)
scrap https://example.com

# Scraper avec mÃ©thode avancÃ©e
scrap-advanced https://example.com

# Effacer l'Ã©cran
clear

# Navigation dans l'historique
â†‘ / â†“  # Naviguer dans les 10 derniÃ¨res commandes
```

### Exemples d'Utilisation

#### Scraping de Base
```bash
scrap https://www.amazon.fr/dp/B08N5WRWNW
```
Extrait automatiquement :
- Titres des produits
- Prix
- Images (tÃ©lÃ©chargÃ©es localement)
- Descriptions

#### Scraping AvancÃ©
```bash
scrap-advanced https://www.lemonde.fr
```
Utilise des mÃ©thodes avancÃ©es :
- Rendu JavaScript
- Extraction de contenu principal
- MÃ©tadonnÃ©es structurÃ©es
- Images haute qualitÃ©

## ğŸ”§ FonctionnalitÃ©s AvancÃ©es

### MÃ©thodes d'Extraction

Le scraper avancÃ© utilise plusieurs mÃ©thodes en cascade :

1. **Playwright** : Rendu JavaScript complet
2. **Selenium** : Automatisation navigateur
3. **Requests-HTML** : Rendu JavaScript lÃ©ger
4. **Newspaper3k** : Extraction de contenu journalistique
5. **Readability** : Algorithmes de lisibilitÃ©
6. **Extruct** : DonnÃ©es structurÃ©es (Schema.org, Open Graph)

### Configuration AvancÃ©e

Dans `backend/advanced_scraper.py` :
```python
# ParamÃ¨tres de performance
TIMEOUT = 30              # Timeout HTTP (secondes)
MAX_PAGES = 5             # Nombre max de pages Ã  scraper
USE_JS = True             # Activer le rendu JavaScript
RETRIES = 3               # Nombre de tentatives
```

## ğŸ“Š Formats de DonnÃ©es

### Scraping de Base
```json
{
  "items": [
    {
      "title": "Nom du produit",
      "price": "29.99 â‚¬",
      "img": "https://example.com/image.jpg",
      "img_local": "/images/image.jpg"
    }
  ]
}
```

### Scraping AvancÃ©
```json
{
  "url": "https://example.com",
  "title": "Titre de la page",
  "meta_description": "Description meta",
  "main_content": "Contenu principal extrait",
  "structured_data": {
    "schema_org": [...],
    "open_graph": {...},
    "twitter_cards": {...}
  },
  "images": [
    {
      "src": "https://example.com/img.jpg",
      "alt": "Description",
      "local_path": "/images/img.jpg"
    }
  ],
  "links": [...],
  "metadata": {
    "language": "fr",
    "author": "Auteur",
    "published_date": "2024-01-01"
  }
}
```

## ğŸ› ï¸ API Endpoints

### POST `/scrape` - Scraping de Base
```bash
curl -X POST "http://localhost:8000/scrape" \
  -H "Content-Type: application/json" \
  -d '{"url": "https://example.com"}'
```

### POST `/scrape-advanced` - Scraping AvancÃ©
```bash
curl -X POST "http://localhost:8000/scrape-advanced" \
  -H "Content-Type: application/json" \
  -d '{"url": "https://example.com", "use_js": true, "max_pages": 3}'
```

### POST `/extract` - Extraction de Contenu
```bash
curl -X POST "http://localhost:8000/extract" \
  -H "Content-Type: application/json" \
  -d '{"url": "https://example.com"}'
```

## ğŸ¯ Cas d'Usage

### E-commerce
```bash
scrap https://www.fnac.com
scrap https://www.darty.com
scrap https://www.cdiscount.com
```

### ActualitÃ©s
```bash
scrap-advanced https://www.lemonde.fr
scrap-advanced https://www.lefigaro.fr
scrap-advanced https://www.liberation.fr
```

### Blogs et Sites Web
```bash
scrap-advanced https://www.medium.com
scrap-advanced https://www.dev.to
```

## ğŸ” FonctionnalitÃ©s Techniques

### Intelligence Artificielle
- **ModÃ¨le** : GPT-4o-mini (optimisÃ© pour la vitesse et le coÃ»t)
- **Prompt** : Analyse intelligente du HTML pour extraire les Ã©lÃ©ments pertinents
- **SchÃ©ma** : Structure JSON prÃ©dÃ©finie pour la cohÃ©rence

### Gestion des Images
- **TÃ©lÃ©chargement automatique** vers le dossier `backend/images/`
- **DÃ©duplication** basÃ©e sur les URLs d'images
- **Support multi-format** : JPEG, PNG, WebP, AVIF, GIF
- **Fallback** : URL distante si tÃ©lÃ©chargement Ã©choue

### Robustesse
- **Retry automatique** pour les erreurs HTTP 5xx
- **Timeout configurable** pour Ã©viter les blocages
- **Gestion d'erreurs** complÃ¨te avec messages explicites
- **Sanitisation des URLs** pour Ã©viter les injections
- **Anti-dÃ©tection** : User-Agents alÃ©atoires, dÃ©lais

## ğŸ¨ Interface Utilisateur

L'interface s'inspire des terminaux modernes avec :
- **Design sombre** pour rÃ©duire la fatigue oculaire
- **Typographie monospace** pour l'aspect technique
- **Animations fluides** avec Framer Motion
- **Galerie d'images** responsive
- **Navigation clavier** complÃ¨te
- **Historique des commandes** avec recherche

## ğŸš¨ Gestion des Erreurs

L'application gÃ¨re automatiquement :
- **Erreurs rÃ©seau** : Retry avec backoff exponentiel
- **Timeouts** : Limite configurable pour Ã©viter les blocages
- **Erreurs OpenAI** : Messages d'erreur explicites
- **Images manquantes** : Fallback vers URL distante
- **HTML malformÃ©** : Nettoyage automatique avec BeautifulSoup
- **Sites protÃ©gÃ©s** : Utilisation de mÃ©thodes alternatives

## ğŸ“ˆ Performance

- **Extraction rapide** : OptimisÃ© pour les sites e-commerce
- **Cache d'images** : Ã‰vite les tÃ©lÃ©chargements redondants
- **Limite de tokens** : ContrÃ´le des coÃ»ts OpenAI
- **Concurrence** : Gestion asynchrone des requÃªtes
- **MÃ©thodes multiples** : Fallback automatique en cas d'Ã©chec

## ğŸ”’ SÃ©curitÃ©

- **Validation des URLs** : VÃ©rification du format et du protocole
- **Sanitisation** : Encodage des caractÃ¨res spÃ©ciaux
- **User-Agent** : Identification claire du bot
- **Rate limiting** : Pause entre les tÃ©lÃ©chargements d'images
- **Anti-bot** : Techniques pour Ã©viter la dÃ©tection

## ğŸš€ DÃ©marrage Rapide pour Test

### Test ImmÃ©diat (5 minutes)

1. **Installer les dÃ©pendances :**
```bash
cd backend && pip install -r requirements.txt
cd ../frontend && npm install
```

2. **Configurer OpenAI :**
```bash
# Dans backend/.env
OPENAI_API_KEY=sk-votre-clÃ©-api-openai
```

3. **DÃ©marrer :**
```bash
# Terminal 1
cd backend && uvicorn main:app --reload --port 8000

# Terminal 2  
cd frontend && npm run dev
```

4. **Tester :**
- Ouvrez `http://localhost:3000`
- Tapez : `scrap https://www.example.com`
- Admirez le rÃ©sultat ! ğŸ‰

## ğŸ“š Ressources

- [Documentation FastAPI](https://fastapi.tiangolo.com/)
- [Documentation Next.js](https://nextjs.org/docs)
- [API OpenAI](https://platform.openai.com/docs)
- [Playwright Documentation](https://playwright.dev/)

## ğŸ¤ Contribution

Les contributions sont les bienvenues ! N'hÃ©sitez pas Ã  :
- Signaler des bugs
- Proposer des amÃ©liorations
- Ajouter de nouvelles fonctionnalitÃ©s
- AmÃ©liorer la documentation

---

**Scraper-LLM** - Transformez n'importe quel site web en donnÃ©es structurÃ©es avec l'intelligence artificielle ! ğŸš€

*DÃ©veloppÃ© avec â¤ï¸ en utilisant FastAPI, Next.js et OpenAI* 